{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavithra64/Retail_sales_prediction/blob/main/Retail_sales_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13V4vwc-qPyy"
      },
      "source": [
        "# Project Title : RETAIL SALES PREDICTION : Predicting sales of a major store chain Rossmann\n",
        "\n",
        "**Problem Description**\n",
        "\n",
        "Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied.\n",
        "You are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set. Note that some stores in the dataset were temporarily closed for refurbishment.\n",
        "\n",
        "**Data Description**\n",
        "\n",
        "Rossmann Stores Data.csv - historical data including Sales\n",
        "store.csv - supplemental information about the stores\n",
        "\n",
        "**Data fields**\n",
        "Most of the fields are self-explanatory. The following are descriptions for those that aren't.\n",
        "\n",
        "Id - an Id that represents a (Store, Date) duple within the test set\n",
        "Store - a unique Id for each store\n",
        "Sales - the turnover for any given day (this is what you are predicting)\n",
        "Customers - the number of customers on a given day\n",
        "Open - an indicator for whether the store was open: 0 = closed, 1 = open\n",
        "StateHoliday - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None\n",
        "SchoolHoliday - indicates if the (Store, Date) was affected by the closure of public schools\n",
        "StoreType - differentiates between 4 different store models: a, b, c, d\n",
        "Assortment - describes an assortment level: a = basic, b = extra, c = extended\n",
        "CompetitionDistance - distance in meters to the nearest competitor store\n",
        "CompetitionOpenSince[Month/Year] - gives the approximate year and month of the time the nearest competitor was opened\n",
        "\n",
        "Promo - indicates whether a store is running a promo on that day\n",
        "Promo2 - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating\n",
        "Promo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2\n",
        "PromoInterval - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP0489zXq8Vf"
      },
      "source": [
        "# Importing Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "B0EmXplSql9Y"
      },
      "outputs": [],
      "source": [
        "# Libraries for EDA\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkpK0nE_rUnV"
      },
      "source": [
        "**LOADING THE DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "xH15MTL8slca",
        "outputId": "625b1fb0-c7a2-400c-b6a0-f2343aa10ac6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3d69276b-c391-4a71-8458-6a2ac2d19466\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3d69276b-c391-4a71-8458-6a2ac2d19466\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Rossmann Stores Data.csv to Rossmann Stores Data (1).csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "xt0UJxbqzL6h",
        "outputId": "a65ec4d2-1878-4f93-ad30-95d740492358"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a9026372-a4a0-49df-8968-9a387b4e962e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a9026372-a4a0-49df-8968-9a387b4e962e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving store.csv to store (2).csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGnZtSvE72hN"
      },
      "outputs": [],
      "source": [
        "store='store.csv'\n",
        "store=pd.read_csv(store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfL831TkrT7z"
      },
      "outputs": [],
      "source": [
        "rsd='Rossmann Stores Data.csv'\n",
        "ross_data=pd.read_csv(rsd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw1WBc0Y5pSs"
      },
      "source": [
        "# Exploratory Data Analysis\n",
        "We have two datasets - 'ross_data' and 'store'. Let's try and understand the basics of these two datasets one by one.\n",
        "\n",
        "**Data Collection and Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0II1DH_vyRB"
      },
      "outputs": [],
      "source": [
        "ross_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TrZEQ27y6EF"
      },
      "outputs": [],
      "source": [
        "# No. of rows and columns of ross_data\n",
        "print('Shape of ross_data is', ross_data.shape)\n",
        "print('No. of rows in ross_data are', ross_data.shape[0])\n",
        "print('No. of columns in ross_data are', ross_data.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TF45ISH8J7B"
      },
      "outputs": [],
      "source": [
        "# Concize summary of ross_data\n",
        "ross_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fri0w_s58NyW"
      },
      "outputs": [],
      "source": [
        "# Descriptive Stats of ross_data dataset\n",
        "ross_data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUhn5Dsp8Vpc"
      },
      "outputs": [],
      "source": [
        "# Top five rows of the dataset\n",
        "store.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeIK5S6c8eAm"
      },
      "outputs": [],
      "source": [
        "# No. of rows and columns\n",
        "print('No of rows in the dataset (store) are', store.shape[0])\n",
        "print('No of columns in the dataset (store) are', store.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NarIpYQ8iZQ"
      },
      "outputs": [],
      "source": [
        "# Descriptive Stats of store dataset\n",
        "store.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyLP0V0o8oRU"
      },
      "outputs": [],
      "source": [
        "# Concise summary of store\n",
        "store.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgIVr87k83UT"
      },
      "source": [
        "# Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MH6Mdwnd8yk5"
      },
      "outputs": [],
      "source": [
        "# Sum of null values\n",
        "store.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ez8cUokG9TGw"
      },
      "outputs": [],
      "source": [
        "# Null value (percentage) of total dataset(store).\n",
        "(store.isnull().sum()/store.shape[0])*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfVSPAMw9W7F"
      },
      "outputs": [],
      "source": [
        "# Distribution of CompetitionDistance\n",
        "sns.distplot(store.CompetitionDistance)\n",
        "plt.title('Distribution of Store Competition Distance (m)')\n",
        "plt.show()\n",
        "\n",
        "# # Distribution of CompetitionOpenSinceYear\n",
        "\n",
        "plt.title('CompetitionOpenSinceYear')\n",
        "sns.distplot(store.CompetitionOpenSinceYear)\n",
        "plt.show()\n",
        "\n",
        "# Distribution of CompetitionOpenSinceMonth\n",
        "\n",
        "plt.title('CompetitionOpenSinceMonth')\n",
        "sns.distplot(store.CompetitionOpenSinceMonth)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NjZayDr9gUs"
      },
      "source": [
        "Dristribution of CompetitionDistance is right skewed so we'll replace the missing values with the median."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2im4kKO9cYO"
      },
      "outputs": [],
      "source": [
        "# Replacing missing values with median value\n",
        "store['CompetitionDistance'].fillna(store['CompetitionDistance'].median() ,inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgQ5iBjD9pVe"
      },
      "source": [
        "Since the columns 'CompetitionOpenSinceMonth' and 'CompetitionOpenSinceYear' both are categorical columns(Months and Years) so we will replace the missing values with mode of particular column and we can see in the code cell below that both columns have only 1 mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBJeW-t59rS1"
      },
      "outputs": [],
      "source": [
        "# Checking for modes\n",
        "print(store['CompetitionOpenSinceMonth'].mode())\n",
        "print(store['CompetitionOpenSinceYear'].mode())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kE8Pk0aV9vfN"
      },
      "outputs": [],
      "source": [
        "# Replacing null values with mode\n",
        "store['CompetitionOpenSinceMonth'].fillna(store['CompetitionOpenSinceMonth'].mode()[0], inplace = True)\n",
        "store['CompetitionOpenSinceYear'].fillna(store['CompetitionOpenSinceYear'].mode()[0], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5_3wNez94Li"
      },
      "outputs": [],
      "source": [
        "# Head\n",
        "store.head(10).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1knc-4L-AVx"
      },
      "source": [
        "We can observe that 'Promo2SinceWeek', 'Promo2SinceYear' and 'PromoInterval' are NaN where Promo2 is zero and they have nearly 50% missing value so we will drop these columns."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping columns from store dataset\n",
        "store.drop('Promo2SinceWeek',axis=1,inplace=True)\n",
        "store.drop('Promo2SinceYear',axis=1,inplace=True)\n",
        "store.drop('PromoInterval',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "Q1NT80TxlRhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ILgWTbPu__Y"
      },
      "outputs": [],
      "source": [
        "store.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDfsBYI6-HyV"
      },
      "outputs": [],
      "source": [
        "# Null values sum (store)\n",
        "store.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LD9oRiUc-Nre"
      },
      "outputs": [],
      "source": [
        "# Null values sum (ross_data)\n",
        "ross_data.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTPOJjgZ-TDq"
      },
      "source": [
        "**Value counts in following columns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtfEsoCP-QBk"
      },
      "outputs": [],
      "source": [
        "# Values Counts\n",
        "print('DayOfWeek:\\n', ross_data['DayOfWeek'].value_counts(), '\\n\\n' )\n",
        "print('Open:\\n', ross_data['Open'].value_counts(), '\\n\\n' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmGsbXIm-dw0"
      },
      "outputs": [],
      "source": [
        "# Value count cont.\n",
        "print('Promo:\\n', ross_data['Promo'].value_counts(), '\\n\\n' )\n",
        "print('StateHoliday:\\n', ross_data['StateHoliday'].value_counts(), '\\n\\n')\n",
        "print('SchoolHoliday:\\n', ross_data['SchoolHoliday'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9qkrHGG-m6S"
      },
      "source": [
        "Checking unique value in StateHoliday because it has two zeros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DyzYjri-l8r"
      },
      "outputs": [],
      "source": [
        "#Checking unique value\n",
        "ross_data['StateHoliday'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXTf16Ui-xuF"
      },
      "source": [
        "In 'StateHoliday' 0 is repeated so, we will fix this using lambda function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUtrxAmk-2dL"
      },
      "source": [
        "**Barplot of StateHoliday vs Sales and StateHoliday vs Customers to check significance of different values.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BRnYLUy-xJ2"
      },
      "outputs": [],
      "source": [
        "fig, (state1, state2) = plt.subplots(1,2,figsize= (16,4))\n",
        "\n",
        "# Barplot of StateHoliday vs Sales\n",
        "state1.title.set_text('StateHoliday vs Sales')\n",
        "sns.barplot(x = 'StateHoliday', y = 'Sales', data = ross_data, ax = state1)\n",
        "\n",
        "# Barplot of StateHoliday vs Customers\n",
        "state2.title.set_text('StateHoliday vs Customers')\n",
        "sns.barplot(x = 'StateHoliday', y = 'Customers', data = ross_data, ax = state2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKaPa1Fl_A6O"
      },
      "source": [
        "There is no significant difference in the value of sales of state holiday type a, b and c as compared to '0'. So, we can treat different types of stateholidays in same way. Thus we can replace state holiday type a, b & c by 1 only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8yA4Er6-8ng"
      },
      "outputs": [],
      "source": [
        "# Replacing 'a', 'b' and 'c' with 1\n",
        "ross_data.StateHoliday.replace({'a': 1,\n",
        "                                'b' : 1,\n",
        "                                'c' : 1\n",
        "                                }, inplace = True )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d3AAX8S_thK"
      },
      "outputs": [],
      "source": [
        "# Verifying\n",
        "ross_data['StateHoliday'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxGi456L_1Jb"
      },
      "outputs": [],
      "source": [
        "# Extracting of data from 'Date' column\n",
        "ross_data['Year'] = pd.to_datetime(ross_data['Date']).dt.year\n",
        "ross_data['Month'] = pd.to_datetime(ross_data['Date']).dt.month\n",
        "ross_data['Day'] = pd.to_datetime(ross_data['Date']).dt.day\n",
        "ross_data['WeekofYear'] = pd.to_datetime(ross_data['Date']).dt.isocalendar().week"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Khs38yGIAJOr"
      },
      "source": [
        "**Distribution of 'Sales'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RE0v94BxAFmm"
      },
      "outputs": [],
      "source": [
        "# distribution plot\n",
        "sns.distplot(ross_data['Sales'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8VwiwkxATBb"
      },
      "source": [
        "**Sales per store type**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rVDnzZ8ARtx"
      },
      "outputs": [],
      "source": [
        "# Barplot\n",
        "sns.barplot(x = store['StoreType'], y = ross_data['Sales'])\n",
        "plt.title('Sales per store type')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSb18zYDAePY"
      },
      "source": [
        "**Sales vs Assortment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vVMhhXEAlMe"
      },
      "outputs": [],
      "source": [
        "# Barplot\n",
        "sns.barplot(x = store['Assortment'], y = ross_data['Sales'])\n",
        "plt.title('Sales vs Assortment')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3Bt8iNkAsk8"
      },
      "source": [
        "**Effect of promotion in sales and number of customers.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMtr9wARAsGt"
      },
      "outputs": [],
      "source": [
        "# Barplot\n",
        "fig, (fig1, fig2) = plt.subplots(1,2,figsize= (16,4))\n",
        "\n",
        "# Barplot of Promo vs Sales\n",
        "fig1.title.set_text('Promo vs Sales')\n",
        "sns.barplot(x = 'Promo', y = 'Sales', data = ross_data, ax = fig1)\n",
        "\n",
        "# Barplot of Promo vs Customers\n",
        "fig2.title.set_text('Promo vs Customers')\n",
        "sns.barplot(x = 'Promo', y = 'Customers', data = ross_data, ax = fig2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvWNeGZCA3J8"
      },
      "source": [
        "Here we can observe that Sales and number of customers increase significantly during promo periods. This shows that promotion have a positive effect of stores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnMeT4IaA8yV"
      },
      "source": [
        "**Sales vs holidays**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ng-RpWoA6EW"
      },
      "outputs": [],
      "source": [
        "# Barplot\n",
        "fig, (fig3, fig4) = plt.subplots(1,2,figsize= (16,4))\n",
        "\n",
        "# StateHoliday vs Sales\n",
        "fig3.title.set_text('StateHoliday vs Sales')\n",
        "sns.barplot(x = 'StateHoliday', y = 'Sales', data = ross_data, ax = fig3)\n",
        "\n",
        "# StateHoliday vs Customers\n",
        "fig4.title.set_text('StateHolidays vs Customers')\n",
        "sns.barplot(x = 'StateHoliday', y = 'Customers', data = ross_data, ax = fig4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4idIT6EBNMI"
      },
      "source": [
        "Only a few stores are open on state holidays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02EAqIHGBTda"
      },
      "source": [
        "**Sales and number of customers on School Holidays**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROPmB7n7BSUM"
      },
      "outputs": [],
      "source": [
        "# Barplot\n",
        "fig, (fig_1, fig_2) = plt.subplots(1,2,figsize= (16,4))\n",
        "\n",
        "# SchoolHoliday vs Sales\n",
        "fig_2.title.set_text('SchoolHoliday vs Sales')\n",
        "sns.barplot(x = 'SchoolHoliday', y = 'Sales', data = ross_data, ax = fig_1)\n",
        "\n",
        "# Schoolholiday vs number of customers\n",
        "fig_2.title.set_text('SchoolHoliday vs Customers')\n",
        "sns.barplot(x = 'SchoolHoliday', y = 'Customers', data = ross_data, ax = fig_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo58sgbDBbdt"
      },
      "source": [
        "\n",
        "We can observe that there is slight increase in sales and number of customers visiting on school holidays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yyQuvmZBnCp"
      },
      "source": [
        "**Open stores per day of week**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uT7Dl07zBOZY"
      },
      "outputs": [],
      "source": [
        "# Opened and closed stores in a week\n",
        "fig, (fig6) = plt.subplots(1,1, figsize = (16,6))\n",
        "sns.countplot(x = 'Open', hue = 'DayOfWeek', data = ross_data, palette= 'deep', ax = fig6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLJDM0FhBtE0"
      },
      "source": [
        "This countplot clearly shows that majority of stores are closed on sunday. Some stores were also closed on other days of the week may be due to public holidays, as stores are usually closed on public holidays and are open during school vacations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAumIVONB10Z"
      },
      "source": [
        "**Sales and number of customers vs days of week**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uytq8DphBsvR"
      },
      "outputs": [],
      "source": [
        "# Barplot\n",
        "fig,(figure1, figure2) = plt.subplots(1,2, figsize = (16, 5))\n",
        "\n",
        "# Sales per day\n",
        "figure1.title.set_text('Sales per day')\n",
        "sns.barplot(x = 'DayOfWeek', y = 'Sales', data = ross_data, order = [1,2,3,4,5,6,7], ax = figure1)\n",
        "\n",
        "# Customers per day\n",
        "figure2.title.set_text('Number of customers per day')\n",
        "sns.barplot(x = 'DayOfWeek', y = 'Customers', data = ross_data, order = [1,2,3,4,5,6,7], ax = figure2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vS7AsTdChuh"
      },
      "source": [
        "This clearly shows most sales are done with the first days, but very less on the last day due to the closed shops on sunday"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6g-wJTKjCo26"
      },
      "source": [
        "**Trend of Average Sales per day of week**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KlEsaebCha7"
      },
      "outputs": [],
      "source": [
        "# Average salesplot\n",
        "fig_a = ross_data.groupby('DayOfWeek')[['Sales']].mean().plot(figsize = (11,5), marker = 'o', color = 'b')\n",
        "fig_a.set_title('Average sales by day of the week')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS4eGOUNCvAe"
      },
      "source": [
        "**Trend of Average number of customers per day of week**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaw1_yU7C1wb"
      },
      "outputs": [],
      "source": [
        "# Avg customers plot\n",
        "fig_b = ross_data.groupby('DayOfWeek')[['Customers']].mean().plot(figsize = (11,5), marker = 'o', color = 'r')\n",
        "fig_b.set_title('Average number of customers per day of the week')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyJpeLgiDByP"
      },
      "source": [
        "**Sales per year**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiO_-nmWDDVZ"
      },
      "outputs": [],
      "source": [
        "# Box plot\n",
        "ross_data.boxplot('Sales', 'Year', figsize= (12,8), fontsize=13 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s6yZcRKDM3b"
      },
      "source": [
        "**Sales per month**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPzYSqxWDJx_"
      },
      "outputs": [],
      "source": [
        "# Boxplot\n",
        "ross_data.boxplot('Sales', 'Month', figsize= (15,8), fontsize=13 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGI1aaYWDYky"
      },
      "source": [
        "\n",
        "**Trend of Sales per month**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5Oj0zdiDTnD"
      },
      "outputs": [],
      "source": [
        "# Avg sales per month\n",
        "fig_c = ross_data.groupby('Month')[['Sales']].mean().plot(figsize = (12,7), marker = 'o', color = 'm')\n",
        "fig_c.set_title('Average Sales per Month')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNmjVuRjDtT_"
      },
      "source": [
        "**Trend of average customers per month**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Vc9fcr6DluM"
      },
      "outputs": [],
      "source": [
        "# Avg customers per month\n",
        "fig_d = ross_data.groupby('Month')[['Customers']].mean().plot(figsize = (12,7), marker = 's', color = 'g')\n",
        "fig_d.set_title('Average Customers per Month')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd-zeMWrD0fO"
      },
      "source": [
        "We can observe the significant increase in sales and number of customers in the month of december. This may be because of Christmas Holidays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mL6_K4GD6kh"
      },
      "source": [
        "**Trend of Average sales per day of Month**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yel1-Ye9D0DV"
      },
      "outputs": [],
      "source": [
        "# Avg sales per day (Monthly)\n",
        "fig_e = ross_data.groupby('Day')[['Sales']].mean().plot(figsize = (12,7), marker = 'o', color = 'c')\n",
        "fig_e.set_title('Average Sales per Day')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H74owKwBELNH"
      },
      "source": [
        "\n",
        "**EDA findings:**\n",
        "\n",
        "The best-selling and most frequently visited by customers is store of type A.\n",
        "\n",
        "For all stores, promotion leads to increased sales and customers.\n",
        "\n",
        "Sales are strongly correlated to the number of customers.\n",
        "\n",
        "Stores open during school holidays have more sales than on normal days.\n",
        "\n",
        "Each time a store participates in a promotion, we see Sales and number of customers increase significantly.\n",
        "\n",
        "More stores are open during school holidays than on public holidays.\n",
        "\n",
        "Sales increase during Christmas week, this may be due to people buying gifts during a Christmas holidays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGvfC03lEXIF"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "943Aku9dEU5k"
      },
      "outputs": [],
      "source": [
        "# Dropping '0' in 'Open' as it indicates that store was closed\n",
        "openstore_df = ross_data[ross_data['Open'] != 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ssn6fo23Eu_g"
      },
      "outputs": [],
      "source": [
        "# we can now drop the column 'Open' as we only included data with 'Open' = 1\n",
        "openstore_df.drop('Open', axis = 1, inplace = True)\n",
        "# Making a Copy\n",
        "ross_df = openstore_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCFe79ImE0Gw"
      },
      "outputs": [],
      "source": [
        "# head\n",
        "ross_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwlxcJcNE7J-"
      },
      "outputs": [],
      "source": [
        "# Distribution of sales after we drop the closed store.\n",
        "sns.distplot(ross_df['Sales'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwkPYfWSFAnZ"
      },
      "source": [
        "We can see that the spike that was present there is now gone."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XW_sRXgFFBfX"
      },
      "outputs": [],
      "source": [
        "# Checking for infinite values\n",
        "np.isinf(ross_df['Sales']).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2f1-uWQFHHn"
      },
      "outputs": [],
      "source": [
        "# Checking for null\n",
        "ross_df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggt0pjvOFKYI"
      },
      "outputs": [],
      "source": [
        "# info\n",
        "ross_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_DZFMJPFOuy"
      },
      "outputs": [],
      "source": [
        "# Creating a list of all relevant numerical features for linear regg.\n",
        "num_features = list(ross_df.describe().columns)\n",
        "\n",
        "# removing 'Store' (ID) and 'Sales' (target variable)\n",
        "num_features.remove('Store')\n",
        "num_features.remove('Sales')\n",
        "\n",
        "num_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9FMeaKwFRuZ"
      },
      "source": [
        "**Relationship between numerical features and target variable.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PaAfglOF9fW"
      },
      "outputs": [],
      "source": [
        "# # Plotting the relationship between each numerical features and the target (Sales) variable\n",
        "for i in num_features:\n",
        "  fig = plt.figure(figsize = (5,5))\n",
        "  feature = ross_df[i]\n",
        "  label = ross_df['Sales']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McBxH7shIuWg"
      },
      "source": [
        "Merging both datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6F8OwwNIDlj"
      },
      "outputs": [],
      "source": [
        "# Merging using left join\n",
        "joined_data = pd.merge(ross_df, store, how= 'left')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbUjKTIwI3Ig"
      },
      "source": [
        "**Label encoding**\n",
        "\n",
        "Assigning each of the following categorical columns an integer value based on alphabetical order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8L49PEs9I5Ja"
      },
      "outputs": [],
      "source": [
        "# Label Encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "joined_data['StoreType'] = label_encoder.fit_transform(joined_data['StoreType'])\n",
        "joined_data['Assortment'] = label_encoder.fit_transform(joined_data['Assortment'])\n",
        "# joined_data['StateHoliday'] = label_encoder.fit_transform(joined_data['StateHoliday'])\n",
        "\n",
        "# Head\n",
        "joined_data.head().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwXouMs2JENu"
      },
      "source": [
        "**Checking for multicolinearity**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joined_data['Date'].head()"
      ],
      "metadata": {
        "id": "Ka8zF82rgaIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNULG8pEJAuy"
      },
      "outputs": [],
      "source": [
        "# correlation heat map\n",
        "plt.figure(figsize = (18,10))\n",
        "joined_data['Date'] = pd.to_datetime(joined_data['Date'])\n",
        "correlation=joined_data.corr()\n",
        "sns.heatmap(abs(correlation), annot = True, cmap = 'YlGnBu')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtVoUjb1JdXK"
      },
      "outputs": [],
      "source": [
        "# Dropping store and date columns because they are irrelevant\n",
        "joined_data.drop(['Store', 'Date'], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKDmCZnOJhUc"
      },
      "source": [
        "**Variance Inflation Factor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q65LeTD8JfDS"
      },
      "outputs": [],
      "source": [
        "# importing vif\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# defining a fuction for vif\n",
        "def calculate_vif(X):\n",
        "    \"\"\"\n",
        "    this function calculates the variance inflation factor\n",
        "    \"\"\"\n",
        "    # VIF calculation\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"variables\"] = X.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "    return(vif)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODarTDr7KTJi"
      },
      "outputs": [],
      "source": [
        "# defining a DataFrame containing on low VIF variables (as we observed above)\n",
        "joined_data_vif = joined_data[[i for i in joined_data.describe().columns if i not in ['Sales','Year','CompetitionOpenSinceYear','Month','WeekOfYear']]].head()\n",
        "joined_data_vif.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFJVQJlvKmqr"
      },
      "source": [
        "# ML Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcRok3jVKh0p"
      },
      "outputs": [],
      "source": [
        "# importing ML models\n",
        "import sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost.sklearn import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4VRXz7DKwhH"
      },
      "outputs": [],
      "source": [
        "# Evaluation Metrics\n",
        "import math\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.metrics import mean_absolute_error as mae"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3ODQV3aK2Ta"
      },
      "source": [
        "We will make a copy of merged dataframe to use it for linear regression and elastic net regression. We will use the log of 'Sales' and 'Customers' columns because it will remove the hetroscadasticity of the linear relationship betwwen then (we observed above in target columns vs numerical freatures)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItUmKQLBK343"
      },
      "outputs": [],
      "source": [
        "# Copy of merged DF\n",
        "joined_df_lr = joined_data.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvKxO0fXK81k"
      },
      "outputs": [],
      "source": [
        "# log10 transformation of 'Sales'\n",
        "joined_df_lr['Sales'] = np.log10(joined_df_lr['Sales'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3c9hN8gPrbR"
      },
      "outputs": [],
      "source": [
        "# Cheching for inf values\n",
        "np.isinf(joined_df_lr['Sales']).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ETjHux1Puni"
      },
      "outputs": [],
      "source": [
        "# droping infinite values after transformation\n",
        "joined_df_lr.drop(joined_df_lr[joined_df_lr['Sales'] == float(\"-inf\")].index,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGi99hawPwp9"
      },
      "outputs": [],
      "source": [
        "# log10 transformation of 'Customers'\n",
        "joined_df_lr['Customers'] = np.log10(joined_df_lr['Customers'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRnyoST4P1DW"
      },
      "outputs": [],
      "source": [
        "# Cheching for inf values again\n",
        "np.isinf(joined_df_lr['Customers']).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EC8UnaVIP7GP"
      },
      "outputs": [],
      "source": [
        "# Declaring Independent and dependent variable for linear regression and elastic net\n",
        "dependent_var = 'Sales'\n",
        "independent_var = joined_data_vif.columns\n",
        "# Creating the datafrmae of independent variables\n",
        "X = joined_df_lr[independent_var].values\n",
        "\n",
        "# Creating the dataframe of dependent variable\n",
        "y = joined_df_lr[dependent_var].values\n",
        "# Splitting the Dataset into Test and Train\n",
        "X = pd.DataFrame(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)\n",
        "\n",
        "# Shape of train data\n",
        "print(X_train.shape)\n",
        "# Shape of test data\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K98Ei5FNQAjl"
      },
      "outputs": [],
      "source": [
        "# Using StandardScaler to normalize the independent variables.\n",
        "scaler = StandardScaler()\n",
        "scaled_X_train = scaler.fit_transform(X_train)\n",
        "scaled_X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfQYm7GBQDR8"
      },
      "source": [
        "**Linear Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SlHMDKrQEuR"
      },
      "outputs": [],
      "source": [
        "# Fitting Multiple Linear Regression to the Training set\n",
        "# Formation of equation\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(scaled_X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOWhmCTzQOEy"
      },
      "outputs": [],
      "source": [
        "# Intercept of equation\n",
        "regressor.intercept_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TI17vVJwQRmh"
      },
      "outputs": [],
      "source": [
        "# Model coefficients\n",
        "regressor.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8jNduZXQTJl"
      },
      "outputs": [],
      "source": [
        "# predicted sales from training dataset\n",
        "y_pred_train = regressor.predict(scaled_X_train)\n",
        "\n",
        "# predicted sales from testing dataset\n",
        "y_pred_test = regressor.predict(scaled_X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lp-pq2PzQaO6"
      },
      "outputs": [],
      "source": [
        "# Defining RMSE function\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "def rmse(x, y):\n",
        "    return sqrt(mean_squared_error(x, y))\n",
        "\n",
        "# Defining MAPE function\n",
        "def mape(x, y):\n",
        "    return np.mean(np.abs((x - y) / x)) * 100\n",
        "# Evaluation Metrics for Linear Regression\n",
        "\n",
        "print(\"Regresion Model Training Score\" , \":\" , regressor.score(scaled_X_train, y_train),\n",
        "      \"Model Test Score\" ,\":\" , regressor.score(scaled_X_test, y_test))\n",
        "\n",
        "print(\"Training RMSE\", \":\", rmse(y_train, y_pred_train),\n",
        "      \"Testing RMSE\", \":\", rmse(y_test, y_pred_test))\n",
        "\n",
        "print(\"Training MAPE\", \":\", mape(y_train, y_pred_train),\n",
        "      \"Testing MAPE\", \":\", mape(y_test, y_pred_test))\n",
        "\n",
        "r2 = r2_score(y_test, y_pred_test)\n",
        "print(\"R2 :\" ,r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpecn219QcYx"
      },
      "outputs": [],
      "source": [
        "# Performance of the model\n",
        "r2s_lr = r2_score(y_train,y_pred_train)\n",
        "r2s2_lr = r2_score(y_test,y_pred_test)\n",
        "\n",
        "mae_lr = mae(y_train,y_pred_train)\n",
        "mae2_lr = mae(y_test,y_pred_test)\n",
        "\n",
        "rmse_lr = math.sqrt(mse(y_train,y_pred_train))\n",
        "rmse2_lr = math.sqrt(mse(y_test,y_pred_test))\n",
        "\n",
        "mse_lr = mse(y_train,y_pred_train)\n",
        "mse2_lr = mse(y_test,y_pred_test)\n",
        "\n",
        "print('Performance of Linear Regression Model:')\n",
        "print('-'*40)\n",
        "\n",
        "print('r2_score train:',r2s_lr)\n",
        "print('r2_score test:',r2s_lr)\n",
        "\n",
        "print('\\nMean absolute error train: %.2f' % mae_lr)\n",
        "print('Mean absolute error test: %.2f' % mae_lr)\n",
        "\n",
        "print('\\nRoot mean squared error train: ', rmse_lr)\n",
        "print('Root mean squared error test: ', rmse_lr)\n",
        "\n",
        "print('\\nMean Sq error train: %.2f' % mse_lr)\n",
        "print('Mean Sq error test: %.2f' % mse_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqLau-vmQg7o"
      },
      "outputs": [],
      "source": [
        "# Showing the optimally fitted line\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.scatter(y_test,y_pred_test)\n",
        "\n",
        "p1 = max(max(y_pred_test),max(y_test))\n",
        "p2 = min(min(y_pred_test),min(y_test))\n",
        "plt.plot([p1,p2],[p1,p2],c='r')\n",
        "plt.xlabel('Actual values')\n",
        "plt.ylabel('Predicted values')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbZ-ckOzQpbz"
      },
      "source": [
        "**Elastic Net Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQQTx2PSQox3"
      },
      "outputs": [],
      "source": [
        "# ElasticNet\n",
        "elasticnet = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
        "# Model fitting\n",
        "elasticnet.fit(scaled_X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scNYDT9uQttx"
      },
      "outputs": [],
      "source": [
        "# Elasticnet score\n",
        "elasticnet.score(scaled_X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZ3NS8AMQzTs"
      },
      "outputs": [],
      "source": [
        "# Predicting test set\n",
        "y_pred_en = elasticnet.predict(scaled_X_test)\n",
        "MSE  = mse(y_test, y_pred_en)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score(y_test,y_pred_en)\n",
        "print(\"R2 :\" ,r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHUuiQffT2ja"
      },
      "source": [
        "**Xgboost Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hs07zcKTz8E"
      },
      "outputs": [],
      "source": [
        "# decalring independent and dependent variables\n",
        "target_col = 'Sales'\n",
        "input_cols = joined_data.columns.drop(target_col)\n",
        "input_cols"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KozBgy3vT-oU"
      },
      "source": [
        "We will use these independent and dependent variables for Xgboost, Decision Tree and Random forest because previous independent and dependent variables contain log10 transformation of 'Sales' and 'Customers' columns also, the following three models can handle multicolinearity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGlyX-FvT_W3"
      },
      "outputs": [],
      "source": [
        "# train test split\n",
        "X_train, X_test, y_train, y_test  = train_test_split(joined_data[input_cols], joined_data[target_col], test_size = 0.2, random_state = 1)\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPooVpSJUDYy"
      },
      "outputs": [],
      "source": [
        "# standard scaler to nornamlise the data\n",
        "scaler = StandardScaler()\n",
        "scale_X_train = scaler.fit_transform(X_train)\n",
        "scale_X_test = scaler.transform(X_test)\n",
        "scale_X_train[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSN7TDT-UKXS"
      },
      "outputs": [],
      "source": [
        "# Building XGBoost Regressor Model:\n",
        "xgb = XGBRegressor(random_state=42, n_jobs=-1, n_estimators=20, max_depth=4)\n",
        "xgb.fit(scale_X_train,y_train)\n",
        "\n",
        "y_predict_xgb = xgb.predict(scale_X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cWKHNEKUL4e"
      },
      "outputs": [],
      "source": [
        "#Performance of the model\n",
        "r2s_xgb = r2_score(y_test,y_predict_xgb)\n",
        "mae_xgb = mae(y_test,y_predict_xgb)\n",
        "rmse_xgb = math.sqrt(mse(y_test,y_predict_xgb))\n",
        "print('Performance of XGBoost Regressor Model:')\n",
        "print('-'*40)\n",
        "print('r2_score:',r2s_xgb)\n",
        "print('Mean absolute error: %.2f' % mae_xgb)\n",
        "print('Root mean squared error: ', rmse_xgb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSlPltPhUSps"
      },
      "source": [
        "**DecisionTree Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b1e4otUUR6p"
      },
      "outputs": [],
      "source": [
        "# Building Decesion Tree Regressor Model:\n",
        "\n",
        "model = DecisionTreeRegressor()\n",
        "model.fit(scale_X_train,y_train)\n",
        "\n",
        "y_predict_dt = model.predict(scale_X_test)\n",
        "# Performance of the model\n",
        "r2s_3 = r2_score(y_test,y_predict_dt)\n",
        "mae3 = mae(y_test,y_predict_dt)\n",
        "rmse3 = math.sqrt(mse(y_test,y_predict_dt))\n",
        "print('Performance of Decesion Tree Model:')\n",
        "print('-'*40)\n",
        "print('r2_score:',r2s_3)\n",
        "print('Mean absolute error: %.2f' % mae3)\n",
        "print('Root mean squared error: ', rmse3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMt2C74XUfKk"
      },
      "source": [
        "**Random Forest Regression Model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building Random Forest Regressor Model:\n",
        "\n",
        "random_forest_model = RandomForestRegressor(n_estimators=100)\n",
        "random_forest_model.fit(scale_X_train,y_train)\n",
        "y_predict_rf = random_forest_model.predict(scale_X_test)\n",
        "\n",
        "# Performance of the model\n",
        "r2s_4 = r2_score(y_test,y_predict_rf)\n",
        "mae4 = mae(y_test,y_predict_rf)\n",
        "rmse4 = math.sqrt(mse(y_test,y_predict_rf))\n",
        "print('Performance of Random Forest Regression Model:')\n",
        "print('-'*40)\n",
        "print('r2_score:', r2s_4)\n",
        "print('Mean absolute error: %.2f' % mae4)\n",
        "print('Root mean squared error: ', rmse4)"
      ],
      "metadata": {
        "id": "BRg1C7mJrsfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdbUKhgUUpHy"
      },
      "source": [
        "**Hyperparameter tuning for RandomForest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOqwtT-bUsWK"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {  'bootstrap': [True], 'max_depth': [5, 10, None], 'max_features': ['auto', 'log2'], 'n_estimators': [5, 6, 7, 8, 9, 10, 11, 12, 13, 15]}\n",
        "rfr = RandomForestRegressor(random_state = 1)\n",
        "g_search = GridSearchCV(estimator = rfr, param_grid = param_grid, cv = 3, n_jobs = 1, verbose = 0, return_train_score=True)\n",
        "g_search.fit(scale_X_train, y_train);\n",
        "\n",
        "print(g_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XAw3nCIUvDs"
      },
      "outputs": [],
      "source": [
        "# Model prediction train set\n",
        "y_pred_RandomForest_tuned_train = g_search.predict(scale_X_train)\n",
        "# Model prediction test set\n",
        "y_pred_RandomForest_tuned_test = g_search.predict(scale_X_test)\n",
        "print(\"Regresion Model Training Score\" , \":\" , g_search.score(scale_X_train, y_train),\n",
        "      \"Model Test Score\" ,\":\" , g_search.score(scale_X_test, y_test))\n",
        "\n",
        "print(\"Training RMSE\", \":\", rmse(y_train, y_pred_RandomForest_tuned_train),\n",
        "      \"Testing RMSE\", \":\", rmse(y_test, y_pred_RandomForest_tuned_test))\n",
        "\n",
        "print(\"Training MAPE\", \":\", mape(y_train, y_pred_RandomForest_tuned_train),\n",
        "      \"Testing MAPE\", \":\", mape(y_test, y_pred_RandomForest_tuned_test))\n",
        "\n",
        "r2 = r2_score(y_test, y_pred_RandomForest_tuned_test)\n",
        "print(\"R2 :\" ,r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37k_-ZWXU228"
      },
      "source": [
        "**Feature importance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmVBw-dYU6RK"
      },
      "outputs": [],
      "source": [
        "#Lets Find Importance of each Feature\n",
        "feature_importance = random_forest_model.feature_importances_\n",
        "# Lets make a dataframe consists of features and values\n",
        "columns_1 = list(X_train.columns)\n",
        "feature_importance_df = pd.DataFrame({'Features':columns_1, 'Importance':feature_importance})\n",
        "feature_importance_df.set_index('Features', inplace=True)\n",
        "feature_importance_df.sort_values(by= 'Importance', ascending = False, inplace = True)\n",
        "feature_importance_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcmfGqL-VEKx"
      },
      "outputs": [],
      "source": [
        "# Feature Importance\n",
        "Features_imp = feature_importance_df.index\n",
        "\n",
        "plt.figure(figsize=(15,12))\n",
        "sns.barplot(y= Features_imp, x=feature_importance_df['Importance'], data = feature_importance_df ).set(title='Feature Importance')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqR1TaoIVKBd"
      },
      "source": [
        "**Observation**:-\n",
        "\n",
        "As per our model; Customer, store Type, CompetitionDistance and Promo are the most important features which are having the most impact on Target Variable i.e. Sales Column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoJb0CDHVRW2"
      },
      "source": [
        "# Conclusion from ML models\n",
        "By Looking at the evaluation metrices obtained on implementing different sort of regression model, we decided to go with the Random Forest Tuned model.The maximum R^2 was seen in tuned Random Forest model with the value 0.97185. It means our best accurate model is able to explain approx/almost 97% of variances in the datasets.\n",
        "\n",
        "Based on our model; Customer, store Type, Promo & CompetitionDistance are the most impactful features which are driving the sales more as compared to other features present in the dataset.\n",
        "\n",
        "**Suggestions from our Analysis**\n",
        "\n",
        "More stores should be encouraged for promotion.\n",
        "\n",
        "Store type 'b' should be increased in number.\n",
        "\n",
        "There is seasonality involved. Hence, the stores should be encouraged to promote and take advantages of the holidays.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0SNNgQxwdpRUVbRav4jnV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}